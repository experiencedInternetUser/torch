# Урок 4: Сверточные сети, кастомные слои

В этом уроке мы:
- Изучим принципы работы сверточных нейронных сетей (CNN)
- Создадим CNN для классификации MNIST и CIFAR
- Реализуем кастомный Residual блок
- Сравним эффективность CNN и полносвязных сетей
- Познакомимся с созданием кастомных слоев в PyTorch

## Структура урока

### Теоретическая часть
- **Сверточные слои** - принципы работы, ядра свертки
- **Pooling слои** - MaxPool, AvgPool, их назначение
- **Архитектуры CNN** - LeNet, AlexNet, современные подходы
- **Residual connections** - принцип работы и преимущества

### Практическая часть

#### Папка `convolutional_basics/`
- `datasets.py` - PyTorch Dataset обертки для MNIST и CIFAR
- `models.py` - сверточные модели с Residual блоками
- `trainer.py` - компактные обучающие и тестирующие циклы
- `utils.py` - вспомогательные функции

## Основные концепции

### Сверточные слои
- **Conv2d**: 2D свертка для изображений
- **Kernel size**: размер ядра свертки (3x3, 5x5, etc.)
- **Stride**: шаг свертки
- **Padding**: дополнение границ изображения
- **Channels**: количество входных и выходных каналов

### Pooling слои
- **MaxPool2d**: максимальное значение в окне
- **AvgPool2d**: среднее значение в окне
- **AdaptivePool**: адаптивный pooling

### Residual Connections
- Прямые связи между слоями
- Помогают обучать очень глубокие сети
- Решают проблему исчезающих градиентов

### Кастомные слои
- Наследование от nn.Module
- Реализация forward метода
- Регистрация параметров
- Обработка градиентов
```

## Требования
См. `requirements.txt`